{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chess Neural Network\n",
        "\n",
        "Building a neural network that learns to play chess based on my gameplay data.\n",
        "\n",
        "## Goal\n",
        "Train a move prediction model to create an AI that plays like me.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler, SequentialSampler\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Load Chess Data\n",
        "\n",
        "Load cleaned data from csv file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>game_id</th>\n",
              "      <th>moves</th>\n",
              "      <th>num_moves</th>\n",
              "      <th>first_move</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>123118274906</td>\n",
              "      <td>[('white', 'e4', True), ('black', 'e6', False)...</td>\n",
              "      <td>90</td>\n",
              "      <td>e4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>123118510404</td>\n",
              "      <td>[('white', 'd4', False), ('black', 'c5', True)...</td>\n",
              "      <td>141</td>\n",
              "      <td>d4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>123118790014</td>\n",
              "      <td>[('white', 'e4', False), ('black', 'e5', True)...</td>\n",
              "      <td>46</td>\n",
              "      <td>e4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>123158939328</td>\n",
              "      <td>[('white', 'e4', False), ('black', 'd5', True)...</td>\n",
              "      <td>88</td>\n",
              "      <td>e4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>123160166430</td>\n",
              "      <td>[('white', 'e4', True), ('black', 'e5', False)...</td>\n",
              "      <td>110</td>\n",
              "      <td>e4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        game_id                                              moves  num_moves  \\\n",
              "0  123118274906  [('white', 'e4', True), ('black', 'e6', False)...         90   \n",
              "1  123118510404  [('white', 'd4', False), ('black', 'c5', True)...        141   \n",
              "2  123118790014  [('white', 'e4', False), ('black', 'e5', True)...         46   \n",
              "3  123158939328  [('white', 'e4', False), ('black', 'd5', True)...         88   \n",
              "4  123160166430  [('white', 'e4', True), ('black', 'e5', False)...        110   \n",
              "\n",
              "  first_move  \n",
              "0         e4  \n",
              "1         d4  \n",
              "2         e4  \n",
              "3         e4  \n",
              "4         e4  "
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"/Users/riteshbhandari/Documents/Dokumentit – Ritesh - MacBook Pro/GitHub/Chess-engine/src/data-analysis/cleaned_data.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 2.1:  Further Pre-processing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['e4', 'e6', 'd4', 'Qh4', 'Nc3', 'f5', 'Nf3', 'Qe7', 'e5', 'Qb4']"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# convert string representation of list to actual list\n",
        "df[\"moves\"] = df[\"moves\"].apply(ast.literal_eval)\n",
        "\n",
        "# saving all the moves to single list to be encoded \n",
        "every_move = []\n",
        "for game in df[\"moves\"]:\n",
        "    for move in game:\n",
        "        every_move.append(move[1])\n",
        "\n",
        "every_move[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of different moves: 1927\n",
            "\n",
            "First 10 moves as numbers: \n",
            "[1051, 946, 1783, 1836, 245, 222, 1115, 1289, 101, 173]\n",
            "\n",
            "First 10 original moves: \n",
            "['e4', 'e6', 'd4', 'Qh4', 'Nc3', 'f5', 'Nf3', 'Qe7', 'e5', 'Qb4']\n"
          ]
        }
      ],
      "source": [
        "# getting all the unique moves\n",
        "unique_moves = set(every_move)  # just the unique moves\n",
        "print(\"Number of different moves:\", len(unique_moves))\n",
        "print()\n",
        "\n",
        "# give move a number\n",
        "move_to_number = {}\n",
        "\n",
        "# turning integer back to moves (for future use)\n",
        "number_to_move= {}\n",
        "\n",
        "for i, move in enumerate(unique_moves):\n",
        "    move_to_number[move] = i\n",
        "    number_to_move[i] = move\n",
        "\n",
        "# turning all the numbers into integers\n",
        "number_moves = []\n",
        "for move in every_move:\n",
        "    number_moves.append(move_to_number[move])\n",
        "\n",
        "# first 10 moves\n",
        "print(\"First 10 moves as numbers: \")\n",
        "print(number_moves[:10])\n",
        "print()\n",
        "\n",
        "# first 10 original moves\n",
        "print(\"First 10 original moves: \")\n",
        "print(every_move[:10]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "moves     [(white, e4, True), (black, e6, False), (white...\n",
            "colors    [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, ...\n",
            "Name: 0, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Create colors per game\n",
        "colors_per_game = []\n",
        "\n",
        "for game in df[\"moves\"]:\n",
        "    \n",
        "    game_colors = []\n",
        "    for move in game:\n",
        "        if move[0] == \"white\":\n",
        "            game_colors.append(1)\n",
        "        else:  # black\n",
        "            game_colors.append(0)\n",
        "    colors_per_game.append(game_colors)\n",
        "\n",
        "# Add to DataFrame\n",
        "df[\"colors\"] = colors_per_game\n",
        "\n",
        "# Check first row\n",
        "print(df[[\"moves\", \"colors\"]].iloc[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "moves            [(white, e4, True), (black, e6, False), (white...\n",
            "teoriat_moves    [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, ...\n",
            "Name: 0, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# turn white or black to integers ( 1  = (White), 0 = (Black) )\n",
        "teoriat_moves_per_game = []\n",
        "\n",
        "for game in df[\"moves\"]:\n",
        "    \n",
        "    game_teoriat = []\n",
        "    for move in game:\n",
        "        if move[2] == True:\n",
        "            game_teoriat.append(1)\n",
        "        else:\n",
        "            game_teoriat.append(0)\n",
        "    teoriat_moves_per_game.append(game_teoriat)\n",
        "\n",
        "# Add to DataFrame\n",
        "df[\"teoriat_moves\"] = teoriat_moves_per_game\n",
        "\n",
        "# Check first row\n",
        "print(df[[\"moves\", \"teoriat_moves\"]].iloc[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(1, 1051, 1), (0, 946, 0), (1, 1783, 1), (0, 1836, 0), (1, 245, 1), (0, 222, 0), (1, 1115, 1), (0, 1289, 0), (1, 101, 1), (0, 173, 0), (1, 1700, 1), (0, 994, 0), (1, 474, 1), (0, 338, 0), (1, 932, 1), (0, 1166, 0), (1, 600, 1), (0, 330, 0), (1, 305, 1), (0, 948, 0), (1, 115, 1), (0, 36, 0), (1, 517, 1), (0, 117, 0), (1, 311, 1), (0, 75, 0), (1, 383, 1), (0, 70, 0), (1, 757, 1), (0, 8, 0), (1, 115, 1), (0, 3, 0), (1, 983, 1), (0, 388, 0), (1, 506, 1), (0, 1575, 0), (1, 1197, 1), (0, 606, 0), (1, 594, 1), (0, 1319, 0), (1, 540, 1), (0, 1923, 0), (1, 626, 1), (0, 596, 0), (1, 506, 1), (0, 78, 0), (1, 1769, 1), (0, 444, 0), (1, 417, 1), (0, 1370, 0), (1, 553, 1), (0, 723, 0), (1, 1801, 1), (0, 330, 0), (1, 637, 1), (0, 866, 0), (1, 506, 1), (0, 1120, 0), (1, 594, 1), (0, 886, 0), (1, 1458, 1), (0, 1488, 0), (1, 1358, 1), (0, 788, 0), (1, 515, 1), (0, 1299, 0), (1, 783, 1), (0, 428, 0), (1, 1458, 1), (0, 1299, 0), (1, 783, 1), (0, 428, 0), (1, 530, 1), (0, 1776, 0), (1, 1893, 1), (0, 1118, 0), (1, 1761, 1), (0, 101, 0), (1, 935, 1), (0, 1850, 0), (1, 1299, 1), (0, 1332, 0), (1, 174, 1), (0, 1051, 0), (1, 862, 1), (0, 620, 0), (1, 506, 1), (0, 692, 0), (1, 1237, 1), (0, 1776, 0)]\n"
          ]
        }
      ],
      "source": [
        "#combine all the features into a single list of tuples seperated by games \n",
        "combined_features_per_game = []\n",
        "\n",
        "for game_idx in range(len(df)):\n",
        "    \n",
        "    game_combined = []\n",
        "    moves = df[\"moves\"].iloc[game_idx]\n",
        "    colors = df[\"colors\"].iloc[game_idx]\n",
        "    teoriat = df[\"teoriat_moves\"].iloc[game_idx]\n",
        "    \n",
        "    for i in range(len(moves)):\n",
        "        # (color, move_as_integer, your_move)\n",
        "        game_combined.append((\n",
        "            colors[i],\n",
        "            move_to_number[moves[i][1]],  # convert move to integer\n",
        "            teoriat[i]\n",
        "        ))\n",
        "    # Append the combined features for the game\n",
        "    combined_features_per_game.append(game_combined)\n",
        "\n",
        "# Add to DataFrame\n",
        "df[\"game_data\"] = combined_features_per_game\n",
        "\n",
        "# Check first game data\n",
        "print(combined_features_per_game[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>game_id</th>\n",
              "      <th>game_data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>123118274906</td>\n",
              "      <td>[(1, 1051, 1), (0, 946, 0), (1, 1783, 1), (0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>123118510404</td>\n",
              "      <td>[(1, 1783, 0), (0, 1642, 1), (1, 1424, 0), (0,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>123118790014</td>\n",
              "      <td>[(1, 1051, 0), (0, 101, 1), (1, 1115, 0), (0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>123158939328</td>\n",
              "      <td>[(1, 1051, 0), (0, 1424, 1), (1, 101, 0), (0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>123160166430</td>\n",
              "      <td>[(1, 1051, 1), (0, 101, 0), (1, 1440, 1), (0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        game_id                                          game_data\n",
              "0  123118274906  [(1, 1051, 1), (0, 946, 0), (1, 1783, 1), (0, ...\n",
              "1  123118510404  [(1, 1783, 0), (0, 1642, 1), (1, 1424, 0), (0,...\n",
              "2  123118790014  [(1, 1051, 0), (0, 101, 1), (1, 1115, 0), (0, ...\n",
              "3  123158939328  [(1, 1051, 0), (0, 1424, 1), (1, 101, 0), (0, ...\n",
              "4  123160166430  [(1, 1051, 1), (0, 101, 0), (1, 1440, 1), (0, ..."
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# lets drop the columns with unneccessary data \n",
        "df = df.drop(columns=[\"moves\", \"colors\", \"teoriat_moves\", \"first_move\",\"num_moves\"])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2.2: Data Pipeline\n",
        "\n",
        "### Dataset Class\n",
        "Organize chess games into training sequences with sliding windows and padding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of unique moves: 1927\n",
            "Move range: 0 to 1926\n"
          ]
        }
      ],
      "source": [
        "unique_moves = set()\n",
        "for game in df[\"game_data\"]:\n",
        "    for (color, move, your_move) in game:\n",
        "        unique_moves.add(move)\n",
        "\n",
        "print(f\"Number of unique moves: {len(unique_moves)}\")\n",
        "print(f\"Move range: {min(unique_moves)} to {max(unique_moves)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "VOCAB_SIZE = 1928 # 1927 moves and one padding token\n",
        "MAX_SEQUENCE_LENGTH = 6 # for now \n",
        "PAD_TOKEN = 1927 # for not known moves\n",
        "\n",
        "class chessdataset(Dataset):\n",
        "    \n",
        "    def __init__(self, games_data, max_seq_len = 6):\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.pad_token = PAD_TOKEN\n",
        "        self.sequences = []\n",
        "        self.targets = []\n",
        "        \n",
        "        # loop through each games \n",
        "        for game in games_data:\n",
        "            for i in  range(len(game) -1):\n",
        "                start_idx = max(0,i-5)\n",
        "                sequence = game[start_idx : i+1]  \n",
        "            \n",
        "                while len(sequence) <6:\n",
        "                    sequence.insert(0,(0,1927,0))\n",
        "                   \n",
        "                target = game[i+1][1] # the real seventh move \n",
        "                self.sequences.append(sequence)\n",
        "                self.targets.append(target)\n",
        "\n",
        "\n",
        "\n",
        "    # training samples\n",
        "    def __len__ (self):\n",
        "        return len(self.targets)\n",
        "\n",
        "        \n",
        "      # creating batches           \n",
        "    def __getitem__ (self, idx):\n",
        "        sequence = self.sequences[idx]\n",
        "        target = self.targets[idx]\n",
        "\n",
        "        # saving training samples seperately to it's own category\n",
        "        colors = [move_tuple[0] for move_tuple in sequence]\n",
        "        moves = [move_tuple[1] for move_tuple in sequence]\n",
        "        theory = [move_tuple[2] for move_tuple in sequence]\n",
        "        \n",
        "         # total 60 600 training samples\n",
        "        return {\n",
        "            'colors': torch.tensor(colors),\n",
        "            'moves': torch.tensor(moves),\n",
        "            'theory': torch.tensor(theory),\n",
        "            'target': torch.tensor(target), \n",
        "    }                "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total training examples: 60600\n",
            "\n",
            "First training example:\n",
            "Colors: tensor([0, 0, 0, 0, 0, 1])\n",
            "Moves: tensor([1927, 1927, 1927, 1927, 1927, 1051])\n",
            "Theory: tensor([0, 0, 0, 0, 0, 1])\n",
            "Target: 946\n",
            "\n",
            "Shapes:\n",
            "Colors shape: torch.Size([6])\n",
            "Moves shape: torch.Size([6])\n"
          ]
        }
      ],
      "source": [
        "# Create the dataset\n",
        "dataset = chessdataset(df['game_data'])\n",
        "\n",
        "# Check how many training examples\n",
        "print(f\"Total training examples: {len(dataset)}\")\n",
        "\n",
        "# Get one example\n",
        "example = dataset[0]\n",
        "print(f\"\\nFirst training example:\")\n",
        "print(f\"Colors: {example['colors']}\")\n",
        "print(f\"Moves: {example['moves']}\")\n",
        "print(f\"Theory: {example['theory']}\")\n",
        "print(f\"Target: {example['target']}\")\n",
        "\n",
        "print(f\"\\nShapes:\")\n",
        "print(f\"Colors shape: {example['colors'].shape}\")\n",
        "print(f\"Moves shape: {example['moves'].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Purge K-Fold Cross-Validation\n",
        "Setup  Purge cross-validation splits for robust model evaluation and for avoiding data leaks. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "# time based split to 5\n",
        "n_splits = 5\n",
        "\n",
        "#TimeSeriesSplit (time order)\n",
        "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "\n",
        "# gives index range for each fold\n",
        "splits = tscv.split(range(len(dataset)))\n",
        "\n",
        "# train test split\n",
        "fold_num = 1\n",
        "\n",
        "for split in splits:\n",
        "    train = split[0]\n",
        "    test = split[1]\n",
        "\n",
        "\n",
        "    fold_num += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2.3: Build the RNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data parameters\n",
        "BATCH_SIZE = 64\n",
        "MAX_SEQUENCE_LENGTH = 6\n",
        "VOCAB_SIZE = 1928\n",
        "PAD_TOKEN = 1927\n",
        "\n",
        "# Training parameters\n",
        "NUM_EPOCHS = 25\n",
        "LEARNING_RATE = 0.0003  # Changed from 0.001\n",
        "WEIGHT_DECAY = 0.01\n",
        "\n",
        "# Model architecture\n",
        "EMBEDDING_DIM = 128\n",
        "HIDDEN_DIM = 256\n",
        "NUM_LAYERS = 2\n",
        "DROPOUT = 0.3\n",
        "\n",
        "# Model save path\n",
        "MODEL_SAVE_PATH = 'best_chess_model.pth'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "class chessRNN(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size=1928,\n",
        "        embedding_dim=128,\n",
        "        hidden_dim=256,\n",
        "        num_layers=2,\n",
        "        dropout=0.3,\n",
        "        rnn_type=\"gru\"\n",
        "    ):\n",
        "        super(chessRNN, self).__init__()\n",
        "        \n",
        "        # Increased embedding size for color and theory from 6 to 32\n",
        "        self.move_embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=PAD_TOKEN)\n",
        "        self.color_embedding = nn.Embedding(2, 32)\n",
        "        self.theory_embedding = nn.Embedding(2, 32)\n",
        "        \n",
        "        # Layer normalization for stable training\n",
        "        input_dim = embedding_dim + 32 + 32\n",
        "        self.layer_norm = nn.LayerNorm(input_dim)\n",
        "        \n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        \n",
        "        self.rnn = nn.GRU(\n",
        "            input_size=input_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            dropout=dropout if num_layers > 1 else 0,\n",
        "            batch_first=True\n",
        "        )\n",
        "        \n",
        "        # Two-layer output head instead of single layer\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc_intermediate = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "        \n",
        "        # Initialize weights properly\n",
        "        self._init_weights()\n",
        "    \n",
        "    def _init_weights(self):\n",
        "        nn.init.normal_(self.move_embedding.weight, mean=0, std=0.02)\n",
        "        nn.init.normal_(self.color_embedding.weight, mean=0, std=0.02)\n",
        "        nn.init.normal_(self.theory_embedding.weight, mean=0, std=0.02)\n",
        "        nn.init.xavier_uniform_(self.fc_intermediate.weight)\n",
        "        nn.init.zeros_(self.fc_intermediate.bias)\n",
        "        nn.init.xavier_uniform_(self.fc.weight)\n",
        "        nn.init.zeros_(self.fc.bias)\n",
        "    \n",
        "    def forward(self, colors, moves, theory):\n",
        "        move_embedded = self.move_embedding(moves)\n",
        "        color_embedded = self.color_embedding(colors)\n",
        "        theory_embedded = self.theory_embedding(theory)\n",
        "        \n",
        "        combined_embedded = torch.cat([move_embedded, color_embedded, theory_embedded], dim=2)\n",
        "        \n",
        "        # Apply layer normalization\n",
        "        combined_embedded = self.layer_norm(combined_embedded)\n",
        "        \n",
        "        rnn_output, hidden_state = self.rnn(combined_embedded)\n",
        "        last_hidden = hidden_state[-1, :, :]\n",
        "        \n",
        "        # Two-layer output with dropout\n",
        "        x = self.dropout(last_hidden)\n",
        "        x = self.fc_intermediate(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        logits = self.fc(x)\n",
        "        \n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# Final device setup\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Initialize loss function \n",
        "loss_func = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.4 Training the Model\n",
        "\n",
        "| **Phase** | **Details** |\n",
        "|-----------|-------------|\n",
        "| **Local Testing** | Single fold (Fold 5): 50,500 train / 10,100 validation |\n",
        "| **Batch Size** | 64 samples per batch |\n",
        "| **Duration** | 25 epochs  |\n",
        "| **Target** | 40%+ validation accuracy |\n",
        "| **Training** | `train_epoch()` - Forward pass → Loss → Backprop → Update weights |\n",
        "| **Validation** | `validate()` - Evaluate on unseen data (no weight updates) |\n",
        "| **Checkpointing** | Save best model to `best_chess_model.pth` |\n",
        "| **Future (CSC)** | 5-fold cross-validation with GPU acceleration |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training examples: 50500\n",
            "Test examples: 10100\n",
            "Number of training batches: 790\n",
            "Number of test batches: 158\n"
          ]
        }
      ],
      "source": [
        "# Get last fold (Fold 5)\n",
        "train, test = list(tscv.split(range(len(dataset))))[-1]\n",
        "\n",
        "print(f\"Training examples: {len(train)}\")\n",
        "print(f\"Test examples: {len(test)}\")\n",
        "\n",
        "# Create samplers\n",
        "train_sampler = SubsetRandomSampler(train)\n",
        "test_sampler = SequentialSampler(test)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
        "test_loader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=test_sampler)\n",
        "\n",
        "print(f\"Number of training batches: {len(train_loader)}\")\n",
        "print(f\"Number of test batches: {len(test_loader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_epoch(model, dataloader, optimizer, loss_func, device, scheduler=None):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    for batch in dataloader: \n",
        "        colors = batch['colors'].to(device)\n",
        "        moves = batch['moves'].to(device)\n",
        "        theory = batch['theory'].to(device)\n",
        "        targets = batch['target'].to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        logits = model(colors, moves, theory)\n",
        "        loss = loss_func(logits, targets)\n",
        "        loss.backward()\n",
        "        \n",
        "        # Clip gradients to prevent instability\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        # Update learning rate if scheduler is provided\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        _, predicted = torch.max(logits, 1)\n",
        "        correct += (predicted == targets).sum().item()\n",
        "        total += targets.size(0)\n",
        "    \n",
        "    return total_loss / len(dataloader), correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validate(model, dataloader, loss_func, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            colors = batch['colors'].to(device)\n",
        "            moves = batch['moves'].to(device)\n",
        "            theory = batch['theory'].to(device)\n",
        "            targets = batch['target'].to(device)\n",
        "\n",
        "            print(f\"Moves min/max: {moves.min()}/{moves.max()}\")\n",
        "            print(f\"Targets min/max: {targets.min()}/{targets.max()}\")\n",
        "            print(f\"Logits shape: {logits.shape}\")\n",
        "            print(f\"Unique targets: {torch.unique(targets)[:10]}\")\n",
        "            \n",
        "            logits = model(colors, moves, theory)\n",
        "            loss = loss_func(logits, targets)\n",
        "            \n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(logits, 1)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "            total += targets.size(0)\n",
        "\n",
        "            \n",
        "    \n",
        "    return total_loss / len(dataloader), correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training...\n",
            "Training on 50500 examples, validating on 10100 examples\n",
            "Device: cpu\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Reinitialize model with hyperparameters\n",
        "model = chessRNN(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    embedding_dim=EMBEDDING_DIM,\n",
        "    hidden_dim=HIDDEN_DIM,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    dropout=DROPOUT\n",
        ").to(device)\n",
        "\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "scheduler = OneCycleLR(\n",
        "    optimizer, \n",
        "    max_lr=0.001,\n",
        "    epochs=NUM_EPOCHS,\n",
        "    steps_per_epoch=len(train_loader),\n",
        "    pct_start=0.1\n",
        ")\n",
        "\n",
        "best_val_acc = 0\n",
        "\n",
        "print(\"Starting training...\")\n",
        "print(f\"Training on {len(train)} examples, validating on {len(test)} examples\")\n",
        "print(f\"Device: {device}\\n\")\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_loss, train_acc = train_epoch(model, train_loader, optimizer, loss_func, device, scheduler)\n",
        "    val_loss, val_acc = validate(model, test_loader, loss_func, device)\n",
        "    \n",
        "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} | Train Loss: {train_loss:.4f}, Acc: {train_acc:.3f} | Val Loss: {val_loss:.4f}, Acc: {val_acc:.3f}\")\n",
        "    \n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "        print(f\"  ✓ Saved new best: {val_acc:.3f}\")\n",
        "\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(f\"Training complete! Best validation accuracy: {best_val_acc:.3f}\")\n",
        "print(f\"Model saved to: {MODEL_SAVE_PATH}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
