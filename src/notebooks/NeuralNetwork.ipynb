{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chess Neural Network\n",
        "\n",
        "Building a neural network that learns to play chess based on my gameplay data.\n",
        "\n",
        "## Goal\n",
        "Train a move prediction model to create an AI that plays like me.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler, SequentialSampler\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Load Chess Data\n",
        "\n",
        "Load cleaned data from csv file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>game_id</th>\n",
              "      <th>moves</th>\n",
              "      <th>num_moves</th>\n",
              "      <th>first_move</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>123118274906</td>\n",
              "      <td>[('white', 'e4', True), ('black', 'e6', False)...</td>\n",
              "      <td>90</td>\n",
              "      <td>e4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>123118510404</td>\n",
              "      <td>[('white', 'd4', False), ('black', 'c5', True)...</td>\n",
              "      <td>141</td>\n",
              "      <td>d4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>123118790014</td>\n",
              "      <td>[('white', 'e4', False), ('black', 'e5', True)...</td>\n",
              "      <td>46</td>\n",
              "      <td>e4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>123158939328</td>\n",
              "      <td>[('white', 'e4', False), ('black', 'd5', True)...</td>\n",
              "      <td>88</td>\n",
              "      <td>e4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>123160166430</td>\n",
              "      <td>[('white', 'e4', True), ('black', 'e5', False)...</td>\n",
              "      <td>110</td>\n",
              "      <td>e4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        game_id                                              moves  num_moves  \\\n",
              "0  123118274906  [('white', 'e4', True), ('black', 'e6', False)...         90   \n",
              "1  123118510404  [('white', 'd4', False), ('black', 'c5', True)...        141   \n",
              "2  123118790014  [('white', 'e4', False), ('black', 'e5', True)...         46   \n",
              "3  123158939328  [('white', 'e4', False), ('black', 'd5', True)...         88   \n",
              "4  123160166430  [('white', 'e4', True), ('black', 'e5', False)...        110   \n",
              "\n",
              "  first_move  \n",
              "0         e4  \n",
              "1         d4  \n",
              "2         e4  \n",
              "3         e4  \n",
              "4         e4  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"/Users/riteshbhandari/Documents/Dokumentit – Ritesh - MacBook Pro/GitHub/Chess-engine/src/data-analysis/cleaned_data.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 2.1:  Further Pre-processing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['e4', 'e6', 'd4', 'Qh4', 'Nc3', 'f5', 'Nf3', 'Qe7', 'e5', 'Qb4']"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# convert string representation of list to actual list\n",
        "df[\"moves\"] = df[\"moves\"].apply(ast.literal_eval)\n",
        "\n",
        "# saving all the moves to single list to be encoded \n",
        "every_move = []\n",
        "for game in df[\"moves\"]:\n",
        "    for move in game:\n",
        "        every_move.append(move[1])\n",
        "\n",
        "every_move[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of different moves: 1927\n",
            "\n",
            "First 10 moves as numbers: \n",
            "[1776, 1631, 36, 1754, 162, 499, 1142, 356, 15, 87]\n",
            "\n",
            "First 10 original moves: \n",
            "['e4', 'e6', 'd4', 'Qh4', 'Nc3', 'f5', 'Nf3', 'Qe7', 'e5', 'Qb4']\n"
          ]
        }
      ],
      "source": [
        "# getting all the unique moves\n",
        "unique_moves = set(every_move)  # just the unique moves\n",
        "print(\"Number of different moves:\", len(unique_moves))\n",
        "print()\n",
        "\n",
        "# give move a number\n",
        "move_to_number = {}\n",
        "\n",
        "# turning integer back to moves (for future use)\n",
        "number_to_move= {}\n",
        "\n",
        "for i, move in enumerate(unique_moves):\n",
        "    move_to_number[move] = i\n",
        "    number_to_move[i] = move\n",
        "\n",
        "# turning all the numbers into integers\n",
        "number_moves = []\n",
        "for move in every_move:\n",
        "    number_moves.append(move_to_number[move])\n",
        "\n",
        "# first 10 moves\n",
        "print(\"First 10 moves as numbers: \")\n",
        "print(number_moves[:10])\n",
        "print()\n",
        "\n",
        "# first 10 original moves\n",
        "print(\"First 10 original moves: \")\n",
        "print(every_move[:10]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "moves     [(white, e4, True), (black, e6, False), (white...\n",
            "colors    [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, ...\n",
            "Name: 0, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Create colors per game\n",
        "colors_per_game = []\n",
        "\n",
        "for game in df[\"moves\"]:\n",
        "    \n",
        "    game_colors = []\n",
        "    for move in game:\n",
        "        if move[0] == \"white\":\n",
        "            game_colors.append(1)\n",
        "        else:  # black\n",
        "            game_colors.append(0)\n",
        "    colors_per_game.append(game_colors)\n",
        "\n",
        "# Add to DataFrame\n",
        "df[\"colors\"] = colors_per_game\n",
        "\n",
        "# Check first row\n",
        "print(df[[\"moves\", \"colors\"]].iloc[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "moves            [(white, e4, True), (black, e6, False), (white...\n",
            "teoriat_moves    [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, ...\n",
            "Name: 0, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# turn white or black to integers ( 1  = (White), 0 = (Black) )\n",
        "teoriat_moves_per_game = []\n",
        "\n",
        "for game in df[\"moves\"]:\n",
        "    \n",
        "    game_teoriat = []\n",
        "    for move in game:\n",
        "        if move[2] == True:\n",
        "            game_teoriat.append(1)\n",
        "        else:\n",
        "            game_teoriat.append(0)\n",
        "    teoriat_moves_per_game.append(game_teoriat)\n",
        "\n",
        "# Add to DataFrame\n",
        "df[\"teoriat_moves\"] = teoriat_moves_per_game\n",
        "\n",
        "# Check first row\n",
        "print(df[[\"moves\", \"teoriat_moves\"]].iloc[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(1, 1776, 1), (0, 1631, 0), (1, 36, 1), (0, 1754, 0), (1, 162, 1), (0, 499, 0), (1, 1142, 1), (0, 356, 0), (1, 15, 1), (0, 87, 0), (1, 108, 1), (0, 142, 0), (1, 1762, 1), (0, 1077, 0), (1, 346, 1), (0, 1512, 0), (1, 1200, 1), (0, 629, 0), (1, 1903, 1), (0, 624, 0), (1, 367, 1), (0, 328, 0), (1, 1795, 1), (0, 969, 0), (1, 916, 1), (0, 949, 0), (1, 846, 1), (0, 117, 0), (1, 371, 1), (0, 411, 0), (1, 367, 1), (0, 770, 0), (1, 591, 1), (0, 1876, 0), (1, 1365, 1), (0, 807, 0), (1, 715, 1), (0, 198, 0), (1, 1052, 1), (0, 642, 0), (1, 1427, 1), (0, 504, 0), (1, 941, 1), (0, 126, 0), (1, 1365, 1), (0, 1068, 0), (1, 434, 1), (0, 1042, 0), (1, 1922, 1), (0, 1102, 0), (1, 1010, 1), (0, 873, 0), (1, 1143, 1), (0, 629, 0), (1, 1415, 1), (0, 959, 0), (1, 1365, 1), (0, 1560, 0), (1, 1052, 1), (0, 326, 0), (1, 1897, 1), (0, 476, 0), (1, 652, 1), (0, 223, 0), (1, 93, 1), (0, 182, 0), (1, 488, 1), (0, 854, 0), (1, 1897, 1), (0, 182, 0), (1, 488, 1), (0, 854, 0), (1, 1619, 1), (0, 1334, 0), (1, 602, 1), (0, 1836, 0), (1, 1582, 1), (0, 15, 0), (1, 1005, 1), (0, 1043, 0), (1, 182, 1), (0, 716, 0), (1, 268, 1), (0, 1776, 0), (1, 333, 1), (0, 294, 0), (1, 1365, 1), (0, 7, 0), (1, 704, 1), (0, 1334, 0)]\n"
          ]
        }
      ],
      "source": [
        "#combine all the features into a single list of tuples seperated by games \n",
        "combined_features_per_game = []\n",
        "\n",
        "for game_idx in range(len(df)):\n",
        "    \n",
        "    game_combined = []\n",
        "    moves = df[\"moves\"].iloc[game_idx]\n",
        "    colors = df[\"colors\"].iloc[game_idx]\n",
        "    teoriat = df[\"teoriat_moves\"].iloc[game_idx]\n",
        "    \n",
        "    for i in range(len(moves)):\n",
        "        # (color, move_as_integer, your_move)\n",
        "        game_combined.append((\n",
        "            colors[i],\n",
        "            move_to_number[moves[i][1]],  # convert move to integer\n",
        "            teoriat[i]\n",
        "        ))\n",
        "    # Append the combined features for the game\n",
        "    combined_features_per_game.append(game_combined)\n",
        "\n",
        "# Add to DataFrame\n",
        "df[\"game_data\"] = combined_features_per_game\n",
        "\n",
        "# Check first game data\n",
        "print(combined_features_per_game[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>game_id</th>\n",
              "      <th>game_data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>123118274906</td>\n",
              "      <td>[(1, 1776, 1), (0, 1631, 0), (1, 36, 1), (0, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>123118510404</td>\n",
              "      <td>[(1, 36, 0), (0, 1810, 1), (1, 1806, 0), (0, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>123118790014</td>\n",
              "      <td>[(1, 1776, 0), (0, 15, 1), (1, 1142, 0), (0, 4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>123158939328</td>\n",
              "      <td>[(1, 1776, 0), (0, 1806, 1), (1, 15, 0), (0, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>123160166430</td>\n",
              "      <td>[(1, 1776, 1), (0, 15, 0), (1, 377, 1), (0, 12...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        game_id                                          game_data\n",
              "0  123118274906  [(1, 1776, 1), (0, 1631, 0), (1, 36, 1), (0, 1...\n",
              "1  123118510404  [(1, 36, 0), (0, 1810, 1), (1, 1806, 0), (0, 1...\n",
              "2  123118790014  [(1, 1776, 0), (0, 15, 1), (1, 1142, 0), (0, 4...\n",
              "3  123158939328  [(1, 1776, 0), (0, 1806, 1), (1, 15, 0), (0, 1...\n",
              "4  123160166430  [(1, 1776, 1), (0, 15, 0), (1, 377, 1), (0, 12..."
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# lets drop the columns with unneccessary data \n",
        "df = df.drop(columns=[\"moves\", \"colors\", \"teoriat_moves\", \"first_move\",\"num_moves\"])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2.2: Data Pipeline\n",
        "\n",
        "### Dataset Class\n",
        "Organize chess games into training sequences with sliding windows and padding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of unique moves: 1927\n",
            "Move range: 0 to 1926\n"
          ]
        }
      ],
      "source": [
        "unique_moves = set()\n",
        "for game in df[\"game_data\"]:\n",
        "    for (color, move, your_move) in game:\n",
        "        unique_moves.add(move)\n",
        "\n",
        "print(f\"Number of unique moves: {len(unique_moves)}\")\n",
        "print(f\"Move range: {min(unique_moves)} to {max(unique_moves)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "VOCAB_SIZE = 1928 # 1927 moves and one padding token\n",
        "MAX_SEQUENCE_LENGTH = 6 # for now \n",
        "PAD_TOKEN = 1927 # for not known moves\n",
        "\n",
        "class chessdataset(Dataset):\n",
        "    \n",
        "    def __init__(self, games_data, max_seq_len = 6):\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.pad_token = PAD_TOKEN\n",
        "        self.sequences = []\n",
        "        self.targets = []\n",
        "        \n",
        "        # loop through each games \n",
        "        for game in games_data:\n",
        "            for i in  range(len(game) -1):\n",
        "                start_idx = max(0,i-5)\n",
        "                sequence = game[start_idx : i+1]  \n",
        "            \n",
        "                while len(sequence) <6:\n",
        "                    sequence.insert(0,(0,1927,0))\n",
        "                   \n",
        "                target = game[i+1][1] # the real seventh move \n",
        "                self.sequences.append(sequence)\n",
        "                self.targets.append(target)\n",
        "\n",
        "\n",
        "\n",
        "    # training samples\n",
        "    def __len__ (self):\n",
        "        return len(self.targets)\n",
        "\n",
        "        \n",
        "      # creating batches           \n",
        "    def __getitem__ (self, idx):\n",
        "        sequence = self.sequences[idx]\n",
        "        target = self.targets[idx]\n",
        "\n",
        "        # saving training samples seperately to it's own category\n",
        "        colors = [move_tuple[0] for move_tuple in sequence]\n",
        "        moves = [move_tuple[1] for move_tuple in sequence]\n",
        "        theory = [move_tuple[2] for move_tuple in sequence]\n",
        "        \n",
        "         # total 60 600 training samples\n",
        "        return {\n",
        "            'colors': torch.tensor(colors),\n",
        "            'moves': torch.tensor(moves),\n",
        "            'theory': torch.tensor(theory),\n",
        "            'target': torch.tensor(target), \n",
        "    }                "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total training examples: 60600\n",
            "\n",
            "First training example:\n",
            "Colors: tensor([0, 0, 0, 0, 0, 1])\n",
            "Moves: tensor([1927, 1927, 1927, 1927, 1927, 1776])\n",
            "Theory: tensor([0, 0, 0, 0, 0, 1])\n",
            "Target: 1631\n",
            "\n",
            "Shapes:\n",
            "Colors shape: torch.Size([6])\n",
            "Moves shape: torch.Size([6])\n"
          ]
        }
      ],
      "source": [
        "# Create the dataset\n",
        "dataset = chessdataset(df['game_data'])\n",
        "\n",
        "# Check how many training examples\n",
        "print(f\"Total training examples: {len(dataset)}\")\n",
        "\n",
        "# Get one example\n",
        "example = dataset[0]\n",
        "print(f\"\\nFirst training example:\")\n",
        "print(f\"Colors: {example['colors']}\")\n",
        "print(f\"Moves: {example['moves']}\")\n",
        "print(f\"Theory: {example['theory']}\")\n",
        "print(f\"Target: {example['target']}\")\n",
        "\n",
        "print(f\"\\nShapes:\")\n",
        "print(f\"Colors shape: {example['colors'].shape}\")\n",
        "print(f\"Moves shape: {example['moves'].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Purge K-Fold Cross-Validation\n",
        "Setup  Purge cross-validation splits for robust model evaluation and for avoiding data leaks. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# time based split to 5\n",
        "n_splits = 5\n",
        "\n",
        "#TimeSeriesSplit (time order)\n",
        "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "\n",
        "# gives index range for each fold\n",
        "splits = tscv.split(range(len(dataset)))\n",
        "\n",
        "# train test split\n",
        "fold_num = 1\n",
        "\n",
        "for split in splits:\n",
        "    train = split[0]\n",
        "    test = split[1]\n",
        "\n",
        "\n",
        "    fold_num += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2.3: Build the RNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data parameters\n",
        "BATCH_SIZE = 64\n",
        "MAX_SEQUENCE_LENGTH = 6\n",
        "VOCAB_SIZE = 1928\n",
        "PAD_TOKEN = 1927\n",
        "\n",
        "# Training parameters\n",
        "NUM_EPOCHS = 25\n",
        "LEARNING_RATE = 0.0003  # Changed from 0.001\n",
        "WEIGHT_DECAY = 0.01\n",
        "\n",
        "# Model architecture\n",
        "EMBEDDING_DIM = 128\n",
        "HIDDEN_DIM = 256\n",
        "NUM_LAYERS = 2\n",
        "DROPOUT = 0.3\n",
        "\n",
        "# Model save path\n",
        "MODEL_SAVE_PATH = 'best_chess_model.pth'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "class chessRNN(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size=1928,\n",
        "        embedding_dim=128,\n",
        "        hidden_dim=256,\n",
        "        num_layers=2,\n",
        "        dropout=0.3,\n",
        "        rnn_type=\"gru\"\n",
        "    ):\n",
        "        super(chessRNN, self).__init__()\n",
        "        \n",
        "        # Increased embedding size for color and theory from 6 to 32\n",
        "        self.move_embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=PAD_TOKEN)\n",
        "        self.color_embedding = nn.Embedding(2, 32)\n",
        "        self.theory_embedding = nn.Embedding(2, 32)\n",
        "        \n",
        "        # Layer normalization for stable training\n",
        "        input_dim = embedding_dim + 32 + 32\n",
        "        self.layer_norm = nn.LayerNorm(input_dim)\n",
        "        \n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        \n",
        "        self.rnn = nn.GRU(\n",
        "            input_size=input_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            dropout=dropout if num_layers > 1 else 0,\n",
        "            batch_first=True\n",
        "        )\n",
        "        \n",
        "        # Two-layer output head instead of single layer\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc_intermediate = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "        \n",
        "        # Initialize weights properly\n",
        "        self._init_weights()\n",
        "    \n",
        "    def _init_weights(self):\n",
        "        nn.init.normal_(self.move_embedding.weight, mean=0, std=0.02)\n",
        "        nn.init.normal_(self.color_embedding.weight, mean=0, std=0.02)\n",
        "        nn.init.normal_(self.theory_embedding.weight, mean=0, std=0.02)\n",
        "        nn.init.xavier_uniform_(self.fc_intermediate.weight)\n",
        "        nn.init.zeros_(self.fc_intermediate.bias)\n",
        "        nn.init.xavier_uniform_(self.fc.weight)\n",
        "        nn.init.zeros_(self.fc.bias)\n",
        "    \n",
        "    def forward(self, colors, moves, theory):\n",
        "        move_embedded = self.move_embedding(moves)\n",
        "        color_embedded = self.color_embedding(colors)\n",
        "        theory_embedded = self.theory_embedding(theory)\n",
        "        \n",
        "        combined_embedded = torch.cat([move_embedded, color_embedded, theory_embedded], dim=2)\n",
        "        \n",
        "        # Apply layer normalization\n",
        "        combined_embedded = self.layer_norm(combined_embedded)\n",
        "        \n",
        "        rnn_output, hidden_state = self.rnn(combined_embedded)\n",
        "        last_hidden = hidden_state[-1, :, :]\n",
        "        \n",
        "        # Two-layer output with dropout\n",
        "        x = self.dropout(last_hidden)\n",
        "        x = self.fc_intermediate(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        logits = self.fc(x)\n",
        "        \n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# Final device setup\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Initialize loss function \n",
        "loss_func = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.4 Training the Model\n",
        "\n",
        "| **Phase** | **Details** |\n",
        "|-----------|-------------|\n",
        "| **Local Testing** | Single fold (Fold 5): 50,500 train / 10,100 validation |\n",
        "| **Batch Size** | 64 samples per batch |\n",
        "| **Duration** | 25 epochs  |\n",
        "| **Target** | 40%+ validation accuracy |\n",
        "| **Training** | `train_epoch()` - Forward pass → Loss → Backprop → Update weights |\n",
        "| **Validation** | `validate()` - Evaluate on unseen data (no weight updates) |\n",
        "| **Checkpointing** | Save best model to `best_chess_model.pth` |\n",
        "| **Future (CSC)** | 5-fold cross-validation with GPU acceleration |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training examples: 30300\n",
            "Validation examples: 10100\n",
            "Test examples (UNSEEN): 10100\n",
            "\n",
            "Number of training batches: 474\n",
            "Number of validation batches: 158\n",
            "Number of test batches: 158\n"
          ]
        }
      ],
      "source": [
        "# Create proper Train/Val/Test split using TimeSeriesSplit\n",
        "all_folds = list(tscv.split(range(len(dataset))))\n",
        "\n",
        "# Use Fold 3 for train/val split, Fold 4 for test\n",
        "train_indices, val_indices = all_folds[2]  # Fold 3: 40,400 train / 10,100 val\n",
        "_, test_indices = all_folds[3]  # Fold 4: 10,100 test (TRULY UNSEEN)\n",
        "\n",
        "print(f\"Training examples: {len(train_indices)}\")\n",
        "print(f\"Validation examples: {len(val_indices)}\")  \n",
        "print(f\"Test examples (UNSEEN): {len(test_indices)}\")\n",
        "\n",
        "# Create samplers\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "val_sampler = SequentialSampler(val_indices)\n",
        "test_sampler = SequentialSampler(test_indices)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
        "val_loader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=val_sampler)\n",
        "test_loader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=test_sampler)\n",
        "\n",
        "print(f\"\\nNumber of training batches: {len(train_loader)}\")\n",
        "print(f\"Number of validation batches: {len(val_loader)}\")\n",
        "print(f\"Number of test batches: {len(test_loader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_epoch(model, dataloader, optimizer, loss_func, device, scheduler=None):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    for batch in dataloader: \n",
        "        colors = batch['colors'].to(device)\n",
        "        moves = batch['moves'].to(device)\n",
        "        theory = batch['theory'].to(device)\n",
        "        targets = batch['target'].to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        logits = model(colors, moves, theory)\n",
        "        loss = loss_func(logits, targets)\n",
        "        loss.backward()\n",
        "        \n",
        "        # Clip gradients to prevent instability\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        # Update learning rate if scheduler is provided\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        _, predicted = torch.max(logits, 1)\n",
        "        correct += (predicted == targets).sum().item()\n",
        "        total += targets.size(0)\n",
        "    \n",
        "    return total_loss / len(dataloader), correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validate(model, dataloader, loss_func, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            colors = batch['colors'].to(device)\n",
        "            moves = batch['moves'].to(device)\n",
        "            theory = batch['theory'].to(device)\n",
        "            targets = batch['target'].to(device)\n",
        "\n",
        "            # Logits calculation MUST happen here\n",
        "            logits = model(colors, moves, theory) \n",
        "            \n",
        "            loss = loss_func(logits, targets)\n",
        "            \n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(logits, 1)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "            total += targets.size(0)\n",
        "\n",
        "            \n",
        "    \n",
        "    return total_loss / len(dataloader), correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training...\n",
            "Training on 30300 examples\n",
            "Validating on 10100 examples\n",
            "Device: cpu\n",
            "\n",
            "Epoch 1/25 | Train Loss: 6.7384, Acc: 0.016 | Val Loss: 6.0922, Acc: 0.032\n",
            "  ✓ Saved new best: 0.032\n",
            "Epoch 2/25 | Train Loss: 5.9420, Acc: 0.048 | Val Loss: 5.4453, Acc: 0.072\n",
            "  ✓ Saved new best: 0.072\n",
            "Epoch 3/25 | Train Loss: 5.5075, Acc: 0.075 | Val Loss: 5.0113, Acc: 0.108\n",
            "  ✓ Saved new best: 0.108\n",
            "Epoch 4/25 | Train Loss: 5.1745, Acc: 0.098 | Val Loss: 4.6656, Acc: 0.137\n",
            "  ✓ Saved new best: 0.137\n",
            "Epoch 5/25 | Train Loss: 4.9073, Acc: 0.116 | Val Loss: 4.3326, Acc: 0.169\n",
            "  ✓ Saved new best: 0.169\n",
            "Epoch 6/25 | Train Loss: 4.6526, Acc: 0.135 | Val Loss: 4.0313, Acc: 0.201\n",
            "  ✓ Saved new best: 0.201\n",
            "Epoch 7/25 | Train Loss: 4.4245, Acc: 0.151 | Val Loss: 3.7444, Acc: 0.240\n",
            "  ✓ Saved new best: 0.240\n",
            "Epoch 8/25 | Train Loss: 4.2020, Acc: 0.171 | Val Loss: 3.4753, Acc: 0.273\n",
            "  ✓ Saved new best: 0.273\n",
            "Epoch 9/25 | Train Loss: 3.9791, Acc: 0.191 | Val Loss: 3.1793, Acc: 0.319\n",
            "  ✓ Saved new best: 0.319\n",
            "Epoch 10/25 | Train Loss: 3.7743, Acc: 0.210 | Val Loss: 2.9067, Acc: 0.379\n",
            "  ✓ Saved new best: 0.379\n",
            "Epoch 11/25 | Train Loss: 3.5847, Acc: 0.232 | Val Loss: 2.6736, Acc: 0.426\n",
            "  ✓ Saved new best: 0.426\n",
            "Epoch 12/25 | Train Loss: 3.3792, Acc: 0.260 | Val Loss: 2.4266, Acc: 0.479\n",
            "  ✓ Saved new best: 0.479\n",
            "Epoch 13/25 | Train Loss: 3.1941, Acc: 0.284 | Val Loss: 2.2049, Acc: 0.521\n",
            "  ✓ Saved new best: 0.521\n",
            "Epoch 14/25 | Train Loss: 3.0188, Acc: 0.312 | Val Loss: 2.0018, Acc: 0.558\n",
            "  ✓ Saved new best: 0.558\n",
            "Epoch 15/25 | Train Loss: 2.8767, Acc: 0.335 | Val Loss: 1.8485, Acc: 0.596\n",
            "  ✓ Saved new best: 0.596\n",
            "Epoch 16/25 | Train Loss: 2.7199, Acc: 0.361 | Val Loss: 1.6999, Acc: 0.626\n",
            "  ✓ Saved new best: 0.626\n",
            "Epoch 17/25 | Train Loss: 2.5866, Acc: 0.380 | Val Loss: 1.5698, Acc: 0.657\n",
            "  ✓ Saved new best: 0.657\n",
            "Epoch 18/25 | Train Loss: 2.4668, Acc: 0.404 | Val Loss: 1.4795, Acc: 0.675\n",
            "  ✓ Saved new best: 0.675\n",
            "Epoch 19/25 | Train Loss: 2.3616, Acc: 0.424 | Val Loss: 1.3926, Acc: 0.691\n",
            "  ✓ Saved new best: 0.691\n",
            "Epoch 20/25 | Train Loss: 2.2674, Acc: 0.441 | Val Loss: 1.3352, Acc: 0.703\n",
            "  ✓ Saved new best: 0.703\n",
            "Epoch 21/25 | Train Loss: 2.2112, Acc: 0.453 | Val Loss: 1.2898, Acc: 0.713\n",
            "  ✓ Saved new best: 0.713\n",
            "Epoch 22/25 | Train Loss: 2.1612, Acc: 0.464 | Val Loss: 1.2621, Acc: 0.720\n",
            "  ✓ Saved new best: 0.720\n",
            "Epoch 23/25 | Train Loss: 2.1282, Acc: 0.474 | Val Loss: 1.2476, Acc: 0.723\n",
            "  ✓ Saved new best: 0.723\n",
            "Epoch 24/25 | Train Loss: 2.1020, Acc: 0.476 | Val Loss: 1.2426, Acc: 0.724\n",
            "  ✓ Saved new best: 0.724\n",
            "Epoch 25/25 | Train Loss: 2.0884, Acc: 0.479 | Val Loss: 1.2414, Acc: 0.724\n",
            "  ✓ Saved new best: 0.724\n",
            "\n",
            "==================================================\n",
            "Training complete! Best validation accuracy: 0.724\n",
            "Model saved to: best_chess_model.pth\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "best_val_acc = 0\n",
        "torch.manual_seed(42)\n",
        "\n",
        "model = chessRNN(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    embedding_dim=EMBEDDING_DIM,\n",
        "    hidden_dim=HIDDEN_DIM,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    dropout=DROPOUT\n",
        ").to(device)\n",
        "\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "scheduler = OneCycleLR(\n",
        "    optimizer, \n",
        "    max_lr=0.001,\n",
        "    epochs=NUM_EPOCHS,\n",
        "    steps_per_epoch=len(train_loader),\n",
        "    pct_start=0.1\n",
        ")\n",
        "\n",
        "print(\"Starting training...\")\n",
        "print(f\"Training on {len(train_indices)} examples\")\n",
        "print(f\"Validating on {len(val_indices)} examples\")\n",
        "print(f\"Device: {device}\\n\")\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_loss, train_acc = train_epoch(model, train_loader, optimizer, loss_func, device, scheduler)\n",
        "    val_loss, val_acc = validate(model, val_loader, loss_func, device)\n",
        "    \n",
        "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} | Train Loss: {train_loss:.4f}, Acc: {train_acc:.3f} | Val Loss: {val_loss:.4f}, Acc: {val_acc:.3f}\")\n",
        "    \n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "        print(f\"  ✓ Saved new best: {val_acc:.3f}\")\n",
        "\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(f\"Training complete! Best validation accuracy: {best_val_acc:.3f}\")\n",
        "print(f\"Model saved to: {MODEL_SAVE_PATH}\")\n",
        "print(f\"{'='*50}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.5 Testing the model real accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TEST RESULTS\n",
            "--------------------\n",
            "Top-1 Accuracy: 0.724 (72.4%)\n",
            "Top-5 Accuracy: 0.918 (91.8%)\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
        "model.eval()\n",
        "\n",
        "test_loss, test_acc = validate(model, test_loader, loss_func, device)\n",
        "\n",
        "top_5_correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        logits = model(batch['colors'].to(device), batch['moves'].to(device), batch['theory'].to(device))\n",
        "        _, top_5 = torch.topk(logits, 5, dim=1)\n",
        "        \n",
        "        for i, target in enumerate(batch['target'].to(device)):\n",
        "            if target in top_5[i]:\n",
        "                top_5_correct += 1\n",
        "            total += 1\n",
        "\n",
        "print(f\"TEST RESULTS\")\n",
        "print(f\"{'-'*20}\")\n",
        "print(f\"Top-1 Accuracy: {test_acc:.3f} ({test_acc*100:.1f}%)\")\n",
        "print(f\"Top-5 Accuracy: {top_5_correct/total:.3f} ({top_5_correct/total*100:.1f}%)\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
